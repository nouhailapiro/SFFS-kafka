# TP Kafka - Black Friday Challenge

## Contexte

Vous √™tes d√©veloppeur dans une startup e-commerce. Le **Black Friday** approche et votre plateforme doit g√©rer un pic de trafic 100x sup√©rieur √† la normale ! 

Actuellement, votre architecture est compos√©e de 4 microservices :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Payment   ‚îÇ ‚îÄ‚îÄ‚ñ∫ ‚îÇ    Order    ‚îÇ ‚îÄ‚îÄ‚ñ∫ ‚îÇ    Email    ‚îÇ     ‚îÇ  Analytics  ‚îÇ
‚îÇ   Service   ‚îÇ     ‚îÇ   Service   ‚îÇ     ‚îÇ   Service   ‚îÇ     ‚îÇ   Service   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Le probl√®me:** Ces services communiquent de mani√®re synchrone. Lors du Black Friday, si un service est surcharg√©, tout le syst√®me s'effondre ! 

**La solution:** Apache Kafka ! 

---

## Objectifs du TP

√Ä la fin de ce TP, vous saurez :

- Cr√©er et configurer des topics Kafka
- Impl√©menter des producers et consumers
- Configurer les partitions et la r√©plication
- Utiliser les consumer groups pour la scalabilit√©
- G√©rer les messages empoisonn√©s (poison pills)
- Impl√©menter du streaming en temps r√©el

---

## Partie 0 : Installation et Setup

### 0.1 Cloner le projet

```bash
git clone https://github.com/nouhailapiro/SFFS-kafka
cd SFFS-kafka
```

### 0.2 Cr√©er l'environnement virtuel

```bash
# Cr√©er l'environnement
python -m venv venv

# L'activer
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# Installer les d√©pendances
pip install -r requirements.txt
```

### 0.3 Lancer l'infrastructure Kafka

```bash
cd kafka
docker compose up -d
```

V√©rifiez que tout fonctionne :
```bash
docker ps
```

Vous devriez voir 2 containers : `kafka` et `kafka-ui`

### 0.4 Acc√©der √† Kafka UI

Ouvrez votre navigateur : **http://localhost:8080**

C'est votre tableau de bord pour visualiser Kafka !

---

## Partie 1 : D√©couverte de Kafka CLI

Avant de coder, familiarisons-nous avec les commandes Kafka.

### 1.1 Cr√©er votre premier topic

```bash
docker exec -it kafka kafka-topics --bootstrap-server localhost:9092 \
    --create \
    --topic payment-successful \
    --partitions 1 \
    --replication-factor 1
```

**V√©rification:** Allez sur Kafka UI et v√©rifiez que le topic existe.

### 1.2 Cr√©er les autres topics

Cr√©ez les topics suivants avec la m√™me commande :

| Topic | Description |
|-------|-------------|
| `order-created` | √âv√©nements de cr√©ation de commande |
| `email-sent` | √âv√©nements d'envoi d'emails
| `dlq-payment` | Dead Letter Queue pour les erreurs |

<details>
<summary>Solution</summary>

```bash
docker exec -it kafka kafka-topics --bootstrap-server localhost:9092 \
    --create --topic order-created --partitions 1 --replication-factor 1

docker exec -it kafka kafka-topics --bootstrap-server localhost:9092 \
    --create --topic email-sent --partitions 1 --replication-factor 1

docker exec -it kafka kafka-topics --bootstrap-server localhost:9092 \
    --create --topic dlq-payment --partitions 1 --replication-factor 1
```
</details>

### 1.3 Lister les topics

```bash
docker exec -it kafka kafka-topics --bootstrap-server localhost:9092 --list
```

### 1.4 Tester avec la console

**Terminal 1 - Consumer:**
```bash
docker exec -it kafka kafka-console-consumer \
    --bootstrap-server localhost:9092 \
    --topic payment-successful \
    --from-beginning
```

**Terminal 2 - Producer:**
```bash
docker exec -it kafka kafka-console-producer \
    --bootstrap-server localhost:9092 \
    --topic payment-successful
```

Tapez un message et appuyez sur Entr√©e. Vous devriez le voir appara√Ætre dans le Terminal 1 !

---

## Partie 2 : Int√©gration Kafka dans les Services

### 2.1 Le Service de Paiement (Producer)

**Objectif:** Modifier `payment-service/service.py` pour envoyer un message Kafka lorsqu'un paiement est effectu√©.

**TODO:**

1. Importer le Producer Kafka depuis `confluent_kafka`
2. Cr√©er la configuration du producer
3. Cr√©er une fonction `delivery_report` pour logger le r√©sultat de l'envoi
4. Produire un message sur le topic `payment-successful` apr√®s traitement du paiement

<details>
<summary>Indices</summary>

```python
from confluent_kafka import Producer

producer_config = {
    "bootstrap.servers": "localhost:9092"
}

producer = Producer(producer_config)

# Pour envoyer un message :
producer.produce(
    topic="payment-successful",
    value=json.dumps(event).encode("utf-8"),
    callback=delivery_report
)
producer.flush()  # Attendre que le message soit envoy√©
```
</details>

<details>
<summary>Solution compl√®te</summary>

```python
from flask import Flask, request, jsonify
import time
import json
from confluent_kafka import Producer

app = Flask(__name__)

producer_config = {
    "bootstrap.servers": "localhost:9092"
}

producer = Producer(producer_config)

def delivery_report(err, msg):
    if err:
        print(f"‚ùå Kafka delivery failed: {err}")
    else:
        print(f"‚úÖ Message sent to topic {msg.topic()} partition[{msg.partition()}]")

@app.route('/payment', methods=['POST'])
def process_payment():
    data = request.get_json()
    cart = data.get('cart')
    user_id = data.get('user_id')
    
    print(f"üí≥ Traitement du paiement pour l'utilisateur {user_id}")
    print(f"Panier: {cart}")
    
    # Cr√©er l'√©v√©nement √† envoyer
    event = {
        "user_id": user_id,
        "cart": cart,
        "timestamp": time.time()
    }

    # Envoyer le message √† Kafka
    producer.produce(
        topic="payment-successful",
        value=json.dumps(event).encode("utf-8"),
        callback=delivery_report
    )
    producer.flush()
    
    time.sleep(2)
    
    return jsonify({
        "status": "success",
        "message": "Paiement effectu√© avec succ√®s",
        "user_id": user_id,
        "cart": cart
    }), 200

@app.errorhandler(Exception)
def handle_error(error):
    return jsonify({"error": str(error)}), 500

if __name__ == '__main__':
    print("üöÄ Service de paiement d√©marr√© sur le port 8000")
    app.run(host='0.0.0.0', port=8000, debug=False)
```
</details>

**Lancez le service :**
```bash
python payment-service/service.py
```

**Dans un autre terminal, testez avec curl :**
```bash
curl -X POST http://localhost:8000/payment \
    -H "Content-Type: application/json" \
    -d '{"user_id": 1, "cart": [{"name": "iPhone", "price": 999, "quantity": 1}]}'
```

**V√©rification:** Regardez le topic `payment-successful` dans Kafka UI. Vous devriez voir votre message !

### 2.2 Le Service de Commande (Consumer)

**Objectif:** Modifier `order-service/service.py` pour consommer les messages du topic `payment-successful`.

**TODO:**

1. Ajouter l'import du consumer Kafka
2. Cr√©er la configuration du consumer
3. Impl√©menter la boucle de consommation
4. Produire un message sur `order-created` apr√®s traitement

<details>
<summary>Indices</summary>

```python
from confluent_kafka import Consumer, Producer

consumer_config = {
        "bootstrap.servers": "localhost:9092",
        "group.id": "order-service-group",
        "auto.offset.reset": "earliest"
}

consumer = Consumer(consumer_config)
consumer.subscribe(["payment-successful"])
```
</details>

<details>
<summary>Solution compl√®te</summary>

```python
from flask import Flask, jsonify
import json
import threading
from confluent_kafka import Consumer, Producer

app = Flask(__name__)

orders = []

# Configuration Kafka
consumer_config = {
        "bootstrap.servers": "localhost:9092",
        "group.id": "order-service-group",
        "auto.offset.reset": "earliest"
}

producer_config = {
        "bootstrap.servers": "localhost:9092"
}

consumer = Consumer(consumer_config)
producer = Producer(producer_config)

def delivery_report(err, msg):
        if err:
                print(f"√âchec envoi: {err}")
        else:
                print(f"Message envoy√© √† {msg.topic()}")

def process_payment_event(message):
        user_id = message.get('user_id')
        cart = message.get('cart')
        
        order = {
                'order_id': len(orders) + 1,
                'user_id': user_id,
                'items': cart,
                'status': 'confirmed'
        }
        
        orders.append(order)
        print(f"Nouvelle commande cr√©√©e: {order}")
        
        # Produire l'√©v√©nement order-created
        producer.produce(
                topic="order-created",
                value=json.dumps(order).encode("utf-8"),
                callback=delivery_report
        )
        producer.poll(0)

def kafka_consumer_loop():
        consumer.subscribe(["payment-successful"])
        print("Consumer d√©marr√©, en √©coute sur 'payment-successful'...")
        
        while True:
                msg = consumer.poll(1.0)
                
                if msg is None:
                        continue
                if msg.error():
                        print(f"Erreur: {msg.error()}")
                        continue
                        
                try:
                        data = json.loads(msg.value().decode('utf-8'))
                        process_payment_event(data)
                except Exception as e:
                        print(f"Erreur de traitement: {e}")

@app.route('/orders', methods=['GET'])
def get_orders():
        return jsonify({"orders": orders}), 200

if __name__ == '__main__':
        # Lancer le consumer dans un thread s√©par√©
        consumer_thread = threading.Thread(target=kafka_consumer_loop, daemon=True)
        consumer_thread.start()
        
        print("Service de commande d√©marr√© sur le port 8001")
        app.run(host='0.0.0.0', port=8001, debug=False)
```
</details>

### 2.3 Le Service Email (Consumer)

**Objectif:** Modifier `email-service/service.py` pour consommer les messages du topic `order-created` et produire des messages sur le topic `email-sent`.

**TODO:**

1. Importer Consumer et Producer Kafka
2. Cr√©er la configuration du consumer pour le topic `order-created`
3. Cr√©er une fonction `send_confirmation_email` pour envoyer les emails
4. Produire un message sur le topic `email-sent` apr√®s envoi
5. Impl√©menter la boucle de consommation

<details>
<summary>Indices</summary>

```python
from confluent_kafka import Consumer, Producer

consumer_config = {
    "bootstrap.servers": "localhost:9092",
    "group.id": "email-service-group",
    "auto.offset.reset": "earliest"
}

producer_config = {
    "bootstrap.servers": "localhost:9092"
}

consumer = Consumer(consumer_config)
producer = Producer(producer_config)
```
</details>

<details>
<summary>Solution compl√®te</summary>

```python
from flask import Flask, jsonify
import json
import threading
from confluent_kafka import Consumer, Producer

app = Flask(__name__)

emails_sent = []

consumer_config = {
        "bootstrap.servers": "localhost:9092",
        "group.id": "email-service-group",
        "auto.offset.reset": "earliest"
}

producer_config = {
    "bootstrap.servers": "localhost:9092"
}

consumer = Consumer(consumer_config)
producer = Producer(producer_config)

def delivery_report(err, msg):
    if err:
        print(f"‚ùå Kafka delivery failed: {err}")
    else:
        print(f"‚úÖ Message sent to {msg.topic()} [partition {msg.partition()}]")


def send_confirmation_email(message):
        user_id = message.get('user_id')
        order_id = message.get('order_id')
        
        email = {
                'to': f'user_{user_id}@example.com',
                'subject': f'Confirmation de commande #{order_id}',
                'body': f'Votre commande #{order_id} a √©t√© confirm√©e!'
        }
        
        emails_sent.append(email)
        print(f"Email envoy√©: {email['subject']} √† {email['to']}")

        # Produire un message dans le topic 'email-sent'
        email_event = {
                'user_id': user_id,
                'order_id': order_id,
                'email_to': email['to'],
                'subject': email['subject'],
                'status': 'sent'
        }
        
        producer.produce(
                topic="email-sent",
                value=json.dumps(email_event).encode("utf-8"),
                callback=delivery_report
        )
        producer.flush()

def kafka_consumer_loop():
        consumer.subscribe(["order-created"])
        print("Consumer d√©marr√©, en √©coute sur 'order-created'...")
        
        while True:
                msg = consumer.poll(1.0)
                
                if msg is None:
                        continue
                if msg.error():
                        print(f"Erreur: {msg.error()}")
                        continue
                        
                try:
                        data = json.loads(msg.value().decode('utf-8'))
                        send_confirmation_email(data)
                except Exception as e:
                        print(f"Erreur de traitement: {e}")

@app.route('/emails', methods=['GET'])
def get_emails():
        return jsonify({"emails_sent": emails_sent}), 200

if __name__ == '__main__':
        consumer_thread = threading.Thread(target=kafka_consumer_loop, daemon=True)
        consumer_thread.start()
        
        print("Service d'email d√©marr√© sur le port 8002")
        app.run(host='0.0.0.0', port=8002, debug=False)
```
</details>

**Lancez le service :**
```bash
python email-service/service.py
```

**V√©rification:** Allez sur Kafka UI et v√©rifiez :
1. Le service √©coute le topic `order-created`
2. Il produit des messages sur le topic `email-sent`
3. Les emails sont stock√©s dans la liste `emails_sent`

**Testez avec curl :**
```bash
# V√©rifier les emails envoy√©s
curl http://localhost:8002/emails
```

### 2.4 Le Service Analytics (Multi-Consumer)

**Objectif:** Modifier `analytics-service/service.py` pour consommer les messages provenant de PLUSIEURS topics (`payment-successful`, `order-created`, `email-sent`) et maintenir des statistiques en temps r√©el.

**TODO:**

1. Importer Consumer Kafka
2. Cr√©er la configuration du consumer
3. S'abonner √† plusieurs topics
4. Impl√©menter des fonctions de tracking pour chaque √©v√©nement
5. Mantenir des statistiques en m√©moire (total paiements, commandes, emails, revenus, utilisateurs uniques)
6. Exposer une API `/analytics` pour consulter les stats

<details>
<summary>Indices</summary>

```python
from confluent_kafka import Consumer

consumer_config = {
    "bootstrap.servers": "localhost:9092",
    "group.id": "analytics-service-group",
    "auto.offset.reset": "earliest",
    "enable.auto.commit": True
}

consumer = Consumer(consumer_config)
# S'abonner √† plusieurs topics
consumer.subscribe(["payment-successful", "order-created", "email-sent"])
```
</details>

<details>
<summary>Solution compl√®te</summary>

```python
from flask import Flask, jsonify
import json
import threading
from confluent_kafka import Consumer

app = Flask(__name__)

# Statistiques en m√©moire
analytics = {
    'total_payments': 0,
    'total_orders': 0,
    'total_emails': 0,
    'total_revenue': 0,
    'users': set()
}

# Configuration du consumer
consumer_config = {
    "bootstrap.servers": "localhost:9092",
    "group.id": "analytics-service-group",
    "auto.offset.reset": "earliest",
    "enable.auto.commit": True
}

consumer = Consumer(consumer_config)

def track_payment(message):
    """
    Enregistre les statistiques de paiement
    """
    user_id = message.get('user_id')
    cart = message.get('cart', [])
    
    analytics['total_payments'] += 1
    analytics['users'].add(user_id)
    
    # Calculer le total du panier (simulation)
    total = sum(item.get('price', 0) * item.get('quantity', 1) for item in cart)
    analytics['total_revenue'] += total
    
    print(f"üìä Paiement enregistr√©: {total}‚Ç¨ pour l'utilisateur {user_id}")

def track_order(message):
    """
    Enregistre les statistiques de commande
    """
    order_id = message.get('order_id')
    
    analytics['total_orders'] += 1
    
    print(f"üìä Commande enregistr√©e: #{order_id}")

def track_email(message):
    """
    Enregistre les statistiques d'email
    """
    order_id = message.get('order_id')
    email_to = message.get('email_to')
    
    analytics['total_emails'] += 1
    
    print(f"üìä Email enregistr√©: {email_to} pour commande #{order_id}")


@app.route('/analytics', methods=['GET'])
def get_analytics():
    stats = analytics.copy()
    stats['unique_users'] = len(analytics['users'])
    stats['users'] = list(analytics['users'])
    
    return jsonify(stats), 200


def kafka_consumer_loop():
    """
    Thread qui consomme les messages de plusieurs topics
    """
    # S'abonner √† plusieurs topics
    consumer.subscribe(["payment-successful", "order-created", "email-sent"])
    print("üéß Consumer d√©marr√©, √©coute sur 3 topics:")
    print("   - payment-successful")
    print("   - order-created")
    print("   - email-sent")
    
    try:
        while True:
            msg = consumer.poll(timeout=1.0)
            
            if msg is None:
                continue
            
            if msg.error():
                print(f"‚ùå Consumer error: {msg.error()}")
                continue
            
            # D√©coder le message
            try:
                message_value = json.loads(msg.value().decode('utf-8'))
                topic = msg.topic()
                
                print(f"üì® Message re√ßu de '{topic}'")
                
                # Router vers la bonne fonction selon le topic
                if topic == "payment-successful":
                    track_payment(message_value)
                elif topic == "order-created":
                    track_order(message_value)
                elif topic == "email-sent":
                    track_email(message_value)
                else:
                    print(f"‚ö†Ô∏è Topic inconnu: {topic}")
                    
            except json.JSONDecodeError as e:
                print(f"‚ùå Erreur de d√©codage JSON: {e}")
            except Exception as e:
                print(f"‚ùå Erreur lors du traitement: {e}")
                
    except KeyboardInterrupt:
        print("üõë Arr√™t du consumer...")
    finally:
        consumer.close()

if __name__ == '__main__':
    # D√©marrer le consumer Kafka dans un thread s√©par√©
    consumer_thread = threading.Thread(target=kafka_consumer_loop, daemon=True)
    consumer_thread.start()

    print("üöÄ Service d'analytics d√©marr√© sur le port 8003")
    print("‚è≥ En attente d'√©v√©nements...")
    app.run(host='0.0.0.0', port=8003, debug=False)
```
</details>

**Lancez le service :**
```bash
python analytics-service/service.py
```


### 2.5 Test de l'int√©gration

Lancez tous les services dans des terminaux s√©par√©s :

```bash
# Terminal 1
python payment-service/service.py

# Terminal 2
python order-service/service.py

# Terminal 3
python email-service/service.py

# Terminal 4
python analytics-service/service.py
```

Envoyez un paiement :
```bash
curl -X POST http://localhost:8000/payment \
    -H "Content-Type: application/json" \
    -d '{"user_id": 42, "cart": [{"name": "MacBook", "price": 1999, "quantity": 1}]}'
```

**V√©rification:** Vous devriez voir :
1. Le paiement trait√© (Terminal 1)
2. La commande cr√©√©e (Terminal 2)
3. L'email envoy√© (Terminal 3)
4. Les statistiques de chaque service qui s'affichent (Terminal 4)

---

## Partie 3 : Simulation Black Friday - Observer le probl√®me

Le but de cette partie est de **voir le probl√®me** : avec une seule partition et un seul consumer, le syst√®me ne peut pas absorber un pic de charge.

### 3.1 Comprendre le LAG

Le **LAG** est la diff√©rence entre :
- Le nombre de messages produits dans Kafka
- Le nombre de messages consomm√©s par votre consumer

```
Messages produits:    [============================] 5000
Messages consomm√©s:   [========]                     1200
                      ‚Üë
                      LAG = 3800 messages en retard!
```

Un LAG √©lev√© signifie que votre consumer n'arrive pas √† suivre le rythme de production.

### 3.2 Ajouter un d√©lai de traitement au consumer

Pour simuler un traitement r√©aliste (acc√®s base de donn√©es, appels API, etc.), modifiez votre `order-service/service.py` pour ajouter un d√©lai dans `process_payment_event`:

```python
import time

def process_payment_event(message):
    user_id = message.get('user_id')
    cart = message.get('cart')
    
    # Simulation d'un traitement lent (acc√®s DB, validation, etc.)
    time.sleep(0.1)  # 100ms par message = max 10 messages/seconde
    
    order = {
        'order_id': len(orders) + 1,
        'user_id': user_id,
        'items': cart,
        'status': 'confirmed'
    }
    # ... reste du code
```

### 3.3 Lancer la simulation Black Friday

**Terminal 1 - Lancez votre order-service:**
```bash
python order-service/service.py
```

**Terminal 2 - Injectez 1000 messages dans Kafka:**
```bash
python scripts/kafka_flood.py -n 1000
```

Vous verrez que les 1000 messages sont envoy√©s en quelques secondes.

### 3.4 Observer le LAG

**Terminal 3 - Surveillez le lag en temps r√©el:**
```bash
python scripts/check_consumer_lag.py --monitor
```

Vous devriez voir quelque chose comme :
```
‚è∞ 14:32:15
   order-service-group ‚Üí payment-successful: üî• Lag = 847
‚è∞ 14:32:17
   order-service-group ‚Üí payment-successful: üî• Lag = 823
‚è∞ 14:32:19
   order-service-group ‚Üí payment-successful: üî• Lag = 801
```

**Le consumer traite ~10 messages/seconde, mais on en a inject√© 1000 en 2 secondes !**

### 3.5 Mode intense üî•

Essayez avec plus de messages :

```bash
python scripts/kafka_flood.py --intense  # 5000 messages
```

Le LAG explose ! Votre unique consumer met plusieurs minutes √† rattraper son retard.

**Probl√®me identifi√©:** Avec une seule partition et un seul consumer, le syst√®me ne tient pas la charge !

---

## Partie 4 : Optimisation avec les Partitions et Consumer Groups

### 4.1 Comprendre les partitions

Les partitions permettent de parall√©liser le traitement des messages. **Chaque partition ne peut √™tre lue que par UN seul consumer du m√™me groupe.**

```
                    Topic: payment-successful (3 partitions)
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ   Partition 0   ‚îÇ   Partition 1   ‚îÇ   Partition 2   ‚îÇ
        ‚îÇ   (messages     ‚îÇ   (messages     ‚îÇ   (messages     ‚îÇ
        ‚îÇ    1, 4, 7...)  ‚îÇ    2, 5, 8...)  ‚îÇ    3, 6, 9...)  ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ                 ‚îÇ                 ‚îÇ
                 ‚ñº                 ‚ñº                 ‚ñº
            Consumer 1        Consumer 2        Consumer 3
            (10 msg/s)        (10 msg/s)        (10 msg/s)
                              
                    = 30 messages/seconde au total!
```

**R√®gle importante:** Nombre de consumers ‚â§ Nombre de partitions

### 4.2 Arr√™ter les services et recr√©er les topics

```bash
# Arr√™tez tous vos services (Ctrl+C)

# Supprimer les anciens topics
docker exec -it kafka kafka-topics --bootstrap-server localhost:9092 \
    --delete --topic payment-successful

docker exec -it kafka kafka-topics --bootstrap-server localhost:9092 \
    --delete --topic order-created

# Recr√©er avec 3 partitions
docker exec -it kafka kafka-topics --bootstrap-server localhost:9092 \
    --create --topic payment-successful --partitions 3 --replication-factor 1

docker exec -it kafka kafka-topics --bootstrap-server localhost:9092 \
    --create --topic order-created --partitions 3 --replication-factor 1
```

### 4.3 Lancer 3 instances du consumer

Ouvrez **3 terminaux** et lancez une instance du service dans chacun :

**Terminal 1:**
```bash
python order-service/service.py
```

**Terminal 2:**
```bash
PORT=8011 python order-service/service.py
```

**Terminal 3:**
```bash
PORT=8012 python order-service/service.py
```

> üí° Les 3 instances partagent le m√™me `group.id`, donc Kafka va automatiquement distribuer les partitions entre elles !

### 4.4 V√©rifier la distribution dans Kafka UI

1. Allez sur Kafka UI : http://localhost:8080
2. Cliquez sur **"Consumers"** dans le menu
3. Cliquez sur **"order-service-group"**
4. Observez : chaque consumer a sa propre partition assign√©e !

### 4.5 Relancer la simulation et comparer

**Terminal 4 - Injectez √† nouveau 1000 messages:**
```bash
python scripts/kafka_flood.py -n 1000
```

**Terminal 5 - Surveillez le lag:**
```bash
python scripts/check_consumer_lag.py --monitor
```

### 4.6 Comparer les r√©sultats

| Configuration | D√©bit de traitement | Temps pour 1000 messages |
|--------------|---------------------|--------------------------|
| 1 partition, 1 consumer | ~10 msg/s | ~100 secondes |
| 3 partitions, 3 consumers | ~30 msg/s | ~33 secondes |

**Le lag descend 3x plus vite !**

### 4.7 Test extr√™me

Avec 3 consumers en parall√®le :
```bash
python scripts/kafka_flood.py --intense  # 5000 messages
```

Le syst√®me g√®re maintenant beaucoup mieux la charge !

---

## Partie 5 : Gestion des Messages Empoisonn√©s (20 min)

### 5.1 Qu'est-ce qu'un message empoisonn√© ?

Un "poison pill" est un message malform√© qui peut faire crasher votre consumer :
- JSON invalide
- Champs manquants
- Types incorrects
- Valeurs nulles

### 5.2 Tester les messages empoisonn√©s

```bash
python scripts/poison_pill_test.py
```

Observez les logs de vos consumers. Que se passe-t-il ?

### 5.3 Impl√©menter une gestion robuste

**Objectif:** Modifier le consumer pour :
1. Attraper les erreurs de parsing
2. Logger les erreurs
3. Envoyer les messages en erreur dans une Dead Letter Queue (DLQ)
4. Continuer le traitement des autres messages

<details>
<summary>Solution avec DLQ</summary>

```python
def kafka_consumer_loop():
        consumer.subscribe(["payment-successful"])
        
        while True:
                msg = consumer.poll(1.0)
                
                if msg is None:
                        continue
                if msg.error():
                        print(f"Erreur Kafka: {msg.error()}")
                        continue
                
                raw_value = msg.value()
                
                try:
                        # 1. Parsing JSON
                        data = json.loads(raw_value.decode('utf-8'))
                        
                        # 2. Validation des champs requis
                        if not isinstance(data.get('user_id'), (int, str)):
                                raise ValueError("user_id invalide")
                        if not isinstance(data.get('cart'), list):
                                raise ValueError("cart doit √™tre une liste")
                        
                        # 3. Traitement
                        process_payment_event(data)
                        
                except json.JSONDecodeError as e:
                        print(f"JSON invalide: {e}")
                        send_to_dlq(raw_value, str(e))
                        
                except ValueError as e:
                        print(f"Validation √©chou√©e: {e}")
                        send_to_dlq(raw_value, str(e))
                        
                except Exception as e:
                        print(f"Erreur inattendue: {e}")
                        send_to_dlq(raw_value, str(e))

def send_to_dlq(message, error_reason):
        """Envoie un message dans la Dead Letter Queue"""
        dlq_message = {
                "original_message": message.decode('utf-8') if isinstance(message, bytes) else str(message),
                "error": error_reason,
                "timestamp": time.time()
        }
        
        producer.produce(
                topic="dlq-payment",
                value=json.dumps(dlq_message).encode('utf-8'),
                callback=delivery_report
        )
        producer.poll(0)
        print(f"Message envoy√© √† la DLQ: {error_reason}")
```
</details>

### 5.4 V√©rifier la DLQ

Apr√®s avoir relanc√© le test des poison pills :

```bash
docker exec -it kafka kafka-console-consumer \
    --bootstrap-server localhost:9092 \
    --topic dlq-payment \
    --from-beginning
```

---

## Partie 6 : Analytics en Temps R√©el avec Kafka Streams (15 min)

### 6.1 Objectif

Modifier `analytics-service/service.py` pour afficher des statistiques en temps r√©el.

### 6.2 Impl√©menter le streaming analytics

**Objectif:** Le service analytics doit :
1. Consommer les √©v√©nements `payment-successful` et `order-created`
2. Maintenir des statistiques en m√©moire
3. Exposer ces stats via une API REST

<details>
<summary>Solution</summary>

```python
from flask import Flask, jsonify
import json
import threading
import time
from confluent_kafka import Consumer

app = Flask(__name__)

analytics = {
        'total_payments': 0,
        'total_orders': 0,
        'total_revenue': 0,
        'users': set(),
        'last_updated': None,
        'payments_per_minute': 0,
        'orders_per_minute': 0
}

analytics_lock = threading.Lock()
payment_timestamps = []
order_timestamps = []

consumer_config = {
        "bootstrap.servers": "localhost:9092",
        "group.id": "analytics-service-group",
        "auto.offset.reset": "earliest"
}

consumer = Consumer(consumer_config)

def calculate_rate(timestamps, window_seconds=60):
        """Calcule le taux par minute"""
        now = time.time()
        # Garder seulement les timestamps des derni√®res 60 secondes
        recent = [t for t in timestamps if now - t < window_seconds]
        return len(recent)

def track_payment(message):
        with analytics_lock:
                user_id = message.get('user_id')
                cart = message.get('cart', [])
                
                analytics['total_payments'] += 1
                if user_id:
                        analytics['users'].add(str(user_id))
                
                total = sum(item.get('price', 0) * item.get('quantity', 1) for item in cart if isinstance(item, dict))
                analytics['total_revenue'] += total
                analytics['last_updated'] = time.strftime('%Y-%m-%d %H:%M:%S')
                
                payment_timestamps.append(time.time())
                analytics['payments_per_minute'] = calculate_rate(payment_timestamps)
                
        print(f"[LIVE] Paiement: +{total}EUR | Total: {analytics['total_revenue']}EUR | {analytics['payments_per_minute']} paiements/min")

def track_order(message):
        with analytics_lock:
                analytics['total_orders'] += 1
                analytics['last_updated'] = time.strftime('%Y-%m-%d %H:%M:%S')
                
                order_timestamps.append(time.time())
                analytics['orders_per_minute'] = calculate_rate(order_timestamps)
                
        print(f"[LIVE] Commande #{message.get('order_id')} | Total: {analytics['total_orders']} | {analytics['orders_per_minute']} commandes/min")

def kafka_consumer_loop():
        consumer.subscribe(["payment-successful", "order-created"])
        print("Analytics en √©coute sur 'payment-successful' et 'order-created'...")
        
        while True:
                msg = consumer.poll(1.0)
                
                if msg is None:
                        continue
                if msg.error():
                        print(f"Erreur: {msg.error()}")
                        continue
                        
                try:
                        data = json.loads(msg.value().decode('utf-8'))
                        
                        if msg.topic() == "payment-successful":
                                track_payment(data)
                        elif msg.topic() == "order-created":
                                track_order(data)
                                
                except Exception as e:
                        print(f"Erreur analytics: {e}")

@app.route('/analytics', methods=['GET'])
def get_analytics():
        with analytics_lock:
                stats = analytics.copy()
                stats['unique_users'] = len(analytics['users'])
                stats['users'] = list(analytics['users'])[:10]  # Limiter pour l'affichage
        
        return jsonify(stats), 200

@app.route('/analytics/live', methods=['GET'])
def get_live_stats():
        """Endpoint pour stats en temps r√©el"""
        with analytics_lock:
                return jsonify({
                        'payments_per_minute': analytics['payments_per_minute'],
                        'orders_per_minute': analytics['orders_per_minute'],
                        'total_revenue': analytics['total_revenue'],
                        'last_updated': analytics['last_updated']
                }), 200

if __name__ == '__main__':
        consumer_thread = threading.Thread(target=kafka_consumer_loop, daemon=True)
        consumer_thread.start()
        
        print("Service Analytics d√©marr√© sur le port 8003")
        app.run(host='0.0.0.0', port=8003, debug=False)
```
</details>

### 6.3 Tester le streaming

1. Lancez le service analytics :
```bash
python analytics-service/service.py
```

2. Lancez la simulation Black Friday dans un autre terminal :
```bash
python scripts/black_friday_simulation.py -n 100 -c 20
```

3. Observez les statistiques en temps r√©el :
```bash
# Dans un autre terminal
watch -n 1 'curl -s http://localhost:8003/analytics/live | python -m json.tool'
```

---

## Partie 7 : D√©fis Bonus

### D√©fi 1 : R√©plication pour la haute disponibilit√©

Modifiez le `docker-compose.yml` pour avoir un cluster de 3 brokers Kafka et configurez la r√©plication factor √† 3.

### D√©fi 2 : Exactly-once semantics

Configurez les transactions Kafka pour garantir qu'un message n'est trait√© qu'une seule fois.

### D√©fi 3 : Schema Registry

Ajoutez un Schema Registry et utilisez Avro pour valider le format des messages.

---

## Ressources

- [Documentation Apache Kafka](https://kafka.apache.org/documentation/)
- [Confluent Kafka Python](https://docs.confluent.io/platform/current/clients/confluent-kafka-python/)
- [Kafka UI](https://github.com/provectus/kafka-ui)

---

## Nettoyage

```bash
# Arr√™ter les containers
cd kafka
docker compose down

# Supprimer les volumes (optionnel - supprime toutes les donn√©es)
docker compose down -v

# D√©sactiver l'environnement virtuel
deactivate
```


---
